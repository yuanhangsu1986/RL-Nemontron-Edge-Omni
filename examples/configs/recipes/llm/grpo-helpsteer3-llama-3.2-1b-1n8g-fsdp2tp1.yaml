defaults: ../../grpo_math_1B.yaml
grpo:
  max_num_epochs: 3
  max_num_steps: 500
checkpointing:
  checkpoint_dir: results/grpo-helpsteer3-llama-3.2-1b-5
  metric_name: val:reward
policy:
  model_name: meta-llama/Llama-3.2-1B-Instruct
  max_total_sequence_length: 2048
  generation:
    stop_token_ids:
    - 128009
  dynamic_batching:
    enabled: true
  sequence_packing:
    enabled: false
data:
  prompt_file: null
  dataset_name: HelpSteer3
  split: preference
env:
  math:
    enabled: false
  code_jaccard:
    enabled: true
    num_workers: 8
    processor: helpsteer3_data_processor
logger:
  wandb_enabled: true
  tensorboard_enabled: true
  wandb:
    project: grpo-helpsteer3-llama-3.2-1b
    name: grpo-helpsteer3-llama-3.2-1b-tp${policy.dtensor_cfg.tensor_parallel_size}
  tensorboard:
    log_dir: tb_logs-grpo-helpsteer3-llama-3.2-1b
  mlflow:
    experiment_name: grpo-helpsteer3
    run_name: grpo-helpsteer3-llama-3.2-1b
cluster:
  gpus_per_node: 8
